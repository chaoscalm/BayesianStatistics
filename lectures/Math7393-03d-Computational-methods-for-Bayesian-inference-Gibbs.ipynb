{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Computational methods for Bayesian inference\n",
        "\n",
        "Joshua French\n",
        "\n",
        "To open this information in an interactive Colab notebook, click the\n",
        "Open in Colab graphic below.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jfrench/BayesianStatistics/blob/master/lectures/Math7393-03d-Computational-methods-for-Bayesian-inference-Gibbs.ipynb\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\">\n",
        "</a>\n",
        "\n",
        "We will need certain packages to be available for this notebook. The\n",
        "code below will check if they are installed and install them if\n",
        "necessary.\n",
        "\n",
        "We now plot the sample paths of our chains for the first ten cycles. We\n",
        "use a function, `plot_mcmc_path` from the **bayesutils** package on\n",
        "GitHub."
      ],
      "id": "6b43075b-5592-4a06-bdde-8d9ac63131ca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# see if remotes package is available\n",
        "if (!require(\"remotes\", quietly = TRUE)) {\n",
        "  # if not, then install package\n",
        "  install.packages(\n",
        "    \"remotes\",\n",
        "    repos = \"https://cran.rstudio.com/\"\n",
        "    )\n",
        "}\n",
        "# see if bayesutils package is available\n",
        "if (!require(\"bayesutils\", quietly = TRUE)) {\n",
        "  # if not, then install package\n",
        "  remotes::install_github(\"jfrench/bayesutils\")\n",
        "  library(bayesutils)\n",
        "}"
      ],
      "id": "e4bd2d6f-ccda-4842-a3e4-0d24f93deb70"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to MCMC Methods\n",
        "\n",
        "-   A *stochastic process* is a family of random variables\n",
        "    $\\{\\theta^{(t)}\\}_{t\\in T}$, where $T$ is a subset of $[0, \\infty)$.\n",
        "    -   $\\theta^{(t)}$ denotes the stochastic process at time $t$.\n",
        "    -   The value $\\theta^{(t)}$ takes at time $t$ is known as the\n",
        "        *state* of the process at time $t$.\n",
        "    -   We only consider discrete-time stochastic processes with\n",
        "        $T=\\{0,1,2,…\\}$.\n",
        "-   The *state space* of a stochastic process is the set of all possible\n",
        "    values the process takes.\n",
        "-   A *Markov chain* is a stochastic process\n",
        "    $\\{\\theta^{(0)}, \\theta^{(1)}, \\ldots, \\theta^{(B)}\\}$ such that\n",
        "    $$p(\\theta^{(t+1)} | \\theta^{(t)}, \\theta^{(t-1)}, \\ldots, \\theta^{(0)}) = p(\\theta^{(t+1)} | \\theta^{(t)}).$$\n",
        "    -   $p(\\theta^{(t+1)} | \\theta^{(t)})$ is often called the\n",
        "        *transition distribution*.\n",
        "-   Markov chain Monte Carlo (MCMC) methods attempt to draw samples from\n",
        "    a target distribution when sampling directly from the target\n",
        "    distribution is impossible or computationally expensive.\n",
        "    -   The samples form a Markov chain.\n",
        "-   MCMC methods are constructed so that the (limiting) distribution of\n",
        "    the Markov chain converges to the target distribution.\n",
        "    -   The distribution producing the samples at each step of the\n",
        "        Markov chain becomes more like the target distribution at each\n",
        "        step of the chain.\n",
        "-   A Markov chain converges to a *stationary distribution* when the\n",
        "    Markov chain is irreducible, aperiodic, and positive recurrent.\n",
        "    -   In layman’s terms, for any state $i$ and $j$, we can travel from\n",
        "        $i$ to $j$ in a finite number of steps with probability 1, and\n",
        "        then we will travel back to $i$, but not in a specific pattern\n",
        "        or number of steps.\n",
        "    -   This ensures that we adequately explore the entire support of\n",
        "        our target distribution\n",
        "\n",
        "An effective MCMC method has two main properties:\n",
        "\n",
        "1.  It must be easy to draw from the $p(\\theta^{(t+1)}|\\theta^{(t)})$.\n",
        "2.  The stationary distribution of the Markov chain must match our\n",
        "    target distribution.\n",
        "\n",
        "To construct a Markov chain using an MCMC algorithm:\n",
        "\n",
        "-   Specify an initial value, $\\theta^{(0)}$, for the chain.\n",
        "    -   Often this is a “likely” value of $\\theta$.\n",
        "-   For $t = 1,2, \\ldots, B$, draw samples from\n",
        "    $p(\\theta^{(t+1)}|\\theta^{(t)})$ until $B$ is large enough that the\n",
        "    stationary distribution is reached.\n",
        "-   After the chain has been implemented, check the convergence of the\n",
        "    simulated sequence (or at least verify that there isn’t clear\n",
        "    evidence that the chain hasn’t converged).\n",
        "    -   This is VERY important.\n",
        "\n",
        "Concluding thoughts:\n",
        "\n",
        "-   The *Gibbs* and *Metropolis-Hastings* algorithms are the most\n",
        "    well-known MCMC algorithms.\n",
        "    -   They are designed so that the stationary distribution matches\n",
        "        the target distribution.\n",
        "-   MCMC methods are most popularly used in Bayesian statistics.\n",
        "    -   In Bayesian statistics, the target distribution is generally the\n",
        "        posterior distribution, $p(\\theta | y)$.\n",
        "\n",
        "# Gibbs sampling\n",
        "\n",
        "-   The *Gibbs sampling* algorithm (or *Gibbs sampler*) is the most\n",
        "    popular Markov chain Monte Carlo (MCMC) method.\n",
        "-   The goal of the Gibbs sampler is to draw samples from a target\n",
        "    distribution.\n",
        "-   The Gibbs sampling algorithm produces samples from the target\n",
        "    distribution by successively drawing samples from the full\n",
        "    conditional distributions of the target distribution.\n",
        "    -   The *full conditional distribution* of a random vector is the\n",
        "        distribution of the random vector conditional on all the other\n",
        "        random variables in the joint (i.e., target) distribution.\n",
        "\n",
        "Some notation and terminology:\n",
        "\n",
        "-   Let $\\theta$ be the vector of random variables comprising all\n",
        "    variables of the target distribution, $p(\\theta | y)$.\n",
        "-   Partition $\\theta$ into $d$ components, i.e.,\n",
        "    $\\theta = (\\theta_1, \\theta_2, \\ldots, \\theta_d)$.\n",
        "    -   Each component could be a (single) random variable or a random\n",
        "        vector.\n",
        "-   $\\theta_{-j}$ denotes the vector containing all components in\n",
        "    $\\theta$ except $\\theta_j$, i.e.,\n",
        "    $$\\theta_{-j} = (\\theta_1, \\theta_2, \\ldots, \\theta_{j-1}, \\theta_{j+1}, \\ldots, \\theta_d).$$\n",
        "-   The *full conditional distribution* of $\\theta_j$, denoted\n",
        "    $p(\\theta_j | \\theta_{-j}, y)$, is the distribution of component\n",
        "    $\\theta_j$ conditional on knowing the value of all other components,\n",
        "    $\\theta_{-j}$, and the data, $y$.\n",
        "-   After we have drawn samples from the full conditional distribution\n",
        "    of each component (i.e., drawn samples from\n",
        "    $p(\\theta_{j} | \\theta_{-j}^{(t-1)}, y)$ for $j=1,2,\\ldots,d$) we\n",
        "    have completed a *cycle*.\n",
        "\n",
        "More notation:\n",
        "\n",
        "-   $\\theta_j^{(t)}$ denotes the sampled value of $\\theta_j$ in cycle\n",
        "    $t$ and $\\theta^{(t)}$ the vector of all values sampled in cycle\n",
        "    $t$.\n",
        "-   $\\theta_{-j}^{(t-1)}$ denotes the most current value of all $d$\n",
        "    components of $\\theta$ **except** $\\theta_j$, i.e.,\n",
        "    $$\\theta_{-j}^{(t-1)} = (\\theta_1^{t}, \\theta_2^{t}, \\ldots, \\theta_{j-1}^{(t)}, \\theta_{j+1}^{(t-1)}, \\ldots, \\theta_{d}^{(t-1)}).$$\n",
        "-   $p(\\theta_j | \\theta_{-j}^{(t-1)}, y)$ denotes the full conditional\n",
        "    distribution of $\\theta_j$ conditional on $\\theta_{-j}$ being fixed\n",
        "    at $\\theta_{-j}^{(t-1)}$ and the data being fixed at $y$.\n",
        "\n",
        "The basic Gibbs sampling algorithm is:\n",
        "\n",
        "1.  Choose starting values for all of your components, i.e.,\n",
        "    $\\theta^{(0)} = (\\theta^{(0)}_1, \\theta^{(0)}_2, \\ldots, \\theta^{(0)}_d)$.\n",
        "2.  Set $t = 1$.\n",
        "3.  Draw $\\theta_j^{(t)}$ from the full conditional distribution\n",
        "    $p(\\theta_j | \\theta_{-j}^{(t-1)}, y)$ for $j = 1, 2, \\ldots, d$.\n",
        "4.  Increment $t$.\n",
        "5.  Repeat steps 3 and 4 until convergence.\n",
        "\n",
        "# Example: Gibbs sampler (bivariate normal)\n",
        "\n",
        "This example appears in Bayesian Data Analysis, 3rd edition, by Gelman\n",
        "et al. (2013).\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y | \\theta \\sim N(\\theta, \\Sigma)$ is a bivariate normal distribution\n",
        "with unknown mean $\\theta = (\\theta_1, \\theta_2)$ and known covariance\n",
        "matrix\n",
        "\n",
        "$$\n",
        "\\Sigma =\n",
        "\\begin{bmatrix}\n",
        " 1 & \\rho \\\\\n",
        "\\rho & 1\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "*Prior distribution*\n",
        "\n",
        "The prior for $\\theta$ is an improper uniform over the real line, i.e.,\n",
        "$p(\\theta_1,\\theta_2)\\propto1$.\n",
        "\n",
        "(Why? Because it makes the example easier!)\n",
        "\n",
        "*Posterior distribution*\n",
        "\n",
        "Assuming we observe a single observation $y=(y_1,y_2)$,\n",
        "$$\\theta | y \\sim N(y, \\Sigma).$$\n",
        "\n",
        "Let’s derive the full conditional distributions for $\\theta_1$ and\n",
        "$\\theta_2$.\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "*Full conditional distributions*\n",
        "\n",
        "$\\theta_1 | \\theta_2, y \\sim N(y_1 + \\rho(\\theta_2-y_2),1-\\rho^2)$\n",
        "\n",
        "$\\theta_2 | \\theta_1, y \\sim N(y_2 + \\rho(\\theta_1-y_1), 1-\\rho^2)$\n",
        "\n",
        "Let’s sample from the posterior distribution using a Gibbs sampler\n",
        "assuming $y=(0,0)$ and $\\rho=0.8$.\n",
        "\n",
        "First, we set some of the needed parameters."
      ],
      "id": "eedac660-9d9e-480a-b9e7-adf09e5172db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set parameters\n",
        "rho = .8\n",
        "sigma = sqrt(1 - rho^2)\n",
        "#observed data\n",
        "y1 = 0\n",
        "y2 = 0"
      ],
      "id": "f2701c13-76d4-494e-8d8f-30ceb6c23686"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s create a function, `gibbs`, to do the sampling. The function\n",
        "takes:\n",
        "\n",
        "-   `B`: the number of cycles to run.\n",
        "-   `theta`: the vector of initial values."
      ],
      "id": "3875fccd-a270-4a9d-adb9-797c0f8b442e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gibbs = function(B, theta) {\n",
        "  #create matrix to store samples\n",
        "  theta_sims = matrix(0, nrow = B + 1, ncol = 2)\n",
        "  theta_sims[1,] = theta\n",
        "  # run gibbs sampler for B cycles\n",
        "  for (i in 2:(B+1)) {\n",
        "    # determine full conditional mean for theta1\n",
        "    m1 = y1 + rho * (theta[2] - y2)\n",
        "    # simulate from full conditional distribution for theta1\n",
        "    theta[1] = rnorm(1, m1, sigma)\n",
        "    # determine full conditional mean for theta2\n",
        "    m2 = y2 + rho * (theta[1] - y1)\n",
        "    # simulate from full conditional distribution for theta1\n",
        "    theta[2] = rnorm(1, m2, sigma)\n",
        "    # save sample\n",
        "    theta_sims[i, ] = theta\n",
        "  }\n",
        "  return(theta_sims)\n",
        "}"
      ],
      "id": "6f4c69c0-bdf6-443a-92ae-2ee8a3444cad"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s run an initial chain of 1000 cycles with a starting value\n",
        "$\\theta=(-2.5, -2.5)$."
      ],
      "id": "a1959461-7dee-45e9-bf38-ee7afeb960b8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run initial chain\n",
        "chain1 = gibbs(B = 1000, theta = c(-2.5, -2.5))"
      ],
      "id": "4a6999fb-3aeb-4390-bdea-4026e61e05a6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s draw a “sand” plot of our first chain."
      ],
      "id": "8442a1cd-c638-4023-9d02-8804495c5ba8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot(chain1, pch = \".\",\n",
        "     xlab = expression(theta[1]),\n",
        "     ylab = expression(theta[2]))\n",
        "title(\"Samples from Gibbs sampler\")"
      ],
      "id": "4f71b5fe-697a-4f3f-bff7-00a15bfca1fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now run 3 more chains with different starting values."
      ],
      "id": "9135618c-ae16-4df6-a48a-b2f39e020e30"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain2 = gibbs(B = 1000, c(-2.5, -2.5))\n",
        "chain3 = gibbs(B = 1000, c(2.5, -2.5))\n",
        "chain4 = gibbs(B = 1000, c(2.5, 2.5))"
      ],
      "id": "1b833847-1783-48e3-bd66-4bce4b8fef06"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now plot the samples from all 4 chains in one graphic."
      ],
      "id": "3a74a2a8-7035-4e61-8f7b-966e59d5ae14"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# chain 1\n",
        "plot(chain1, pch = \".\",\n",
        "     xlab = expression(theta[1]),\n",
        "     ylab = expression(theta[2]))\n",
        "# chains 2-4\n",
        "points(chain2, pch = \".\", col = \"orange\")\n",
        "points(chain3, pch = \".\", col = \"blue\")\n",
        "points(chain4, pch = \".\", col = \"grey\")\n",
        "# add legend\n",
        "legend(\"topleft\", pch = 20,\n",
        "       col = c(\"black\", \"orange\", \"blue\", \"grey\"),\n",
        "       legend = c(\"Chain 1\", \"Chain 2\", \"Chain 3\", \"Chain 4\"))\n",
        "title(\"Samples from Gibbs sampler\")"
      ],
      "id": "523a71e6-156d-4d7a-b0db-0b2c453f57e3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now plot the first 10 cycles of the 4 chains using the\n",
        "`plot_mcmc_path` function from the **bayesutils** package.\n",
        "\n",
        "`plot_mcmc_path` takes:\n",
        "\n",
        "-   `x`: a matrix with 2 columns or a list of 2 column matrices.\n",
        "-   `ncycles`: the number of cycles to plot."
      ],
      "id": "94b4f01d-0a40-4873-8c53-b26ccf9c4541"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_mcmc_path(\n",
        "  list(chain1, chain2, chain3, chain4),\n",
        "  ncycles = 10,\n",
        "  xlim = c(-2.5, 2.5),\n",
        "  ylim = c(-2.5, 2.5),\n",
        "  xlab = expression(theta[1]),\n",
        "  ylab = expression(theta[2]),\n",
        "  main = \"First 10 cycles of each chain\"\n",
        ")"
      ],
      "id": "9bc2e4b1-c0e5-44c8-8711-5e79e68d21a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example Normal distribution with $\\mu$ and $\\sigma^2$ unknown and conjugate prior\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y_1,\\ldots,y_n \\mid \\mu,\\sigma^2 \\stackrel{i.i.d.}{\\sim} N(\\mu,\\sigma^2)$.\n",
        "\n",
        "*Prior distribution*\n",
        "\n",
        "$\\mu \\mid \\sigma^2 \\sim N(\\mu_0, \\sigma^2/\\kappa_0)$\n",
        "\n",
        "$\\sigma^2 \\sim \\text{Inv-}\\chi^2_(\\nu_0)(\\sigma_0^2)$\n",
        "\n",
        "where\n",
        "\n",
        "$p(\\sigma^2) \\propto (\\sigma^2)^{-\\left(\\frac{\\nu_0}{2} + 1\\right)} \\exp\\left(-\\frac{\\nu_0 \\sigma_0^2}{2\\sigma^2}\\right)$.\n",
        "\n",
        "*Data density*\n",
        "\n",
        "$p(y \\mid \\mu,\\sigma^2) \\propto$\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "$p(\\mu,\\sigma^2\\mid y) \\propto$\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "Derive the full conditional distributions\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "*Full conditional distributions*\n",
        "\n",
        "$\\mu \\mid \\sigma^2, y \\sim N(\\mu_n, \\tau_n^2)$ with\n",
        "\n",
        "$$\n",
        "\\mu_n = \\frac{\\kappa_0}\n",
        "{\\sigma^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "\\tau_n^2=\\frac{1}{\\frac{\\kappa_0}{\\sigma^2}+\\frac{n}{\\sigma^2}}=\\frac{\\sigma^2}{\\kappa_0+n}.\n",
        "$$ $\\sigma^2 \\mid \\mu, y \\sim \\text{Inv-}\\chi^2_{\\nu_n}(s_n^2)$\n",
        "\n",
        "with\n",
        "\n",
        "$$\n",
        "\\nu_n = \\nu_0 + n + 1\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "s_n^2=\\frac{\\mu_0 \\sigma_0^2+\\kappa_0 (\\mu-\\mu_0 )^2+(n-1) s^2+n(\\bar{y}-\\mu)^2}{\\nu_n}.\n",
        "$$\n",
        "\n",
        "# Example: Midge Data\n",
        "\n",
        "Grogan and Wirth (1981) provide data on the wing length in millimeters\n",
        "of nine members of a species of midge (small, two-winged flies). From\n",
        "these nine measurements, we wish to make inference on the population\n",
        "mean $\\mu$ and population variance $\\sigma^2$. Create a Gibbs sampler\n",
        "for the parameters $\\mu$ and $\\sigma^2$.\n",
        "\n",
        "Studies of other populations suggest that the true mean should be around\n",
        "1.9 mm with a standard deviation of 0.1. However, this population may be\n",
        "different from the others, so we choose $\\kappa_0 = \\nu_0 = 1$ so that\n",
        "the prior distributions are only weakly centered around these estimates\n",
        "from other populations.\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y_1,\\ldots,y_n \\mid \\mu, \\sigma^2 \\stackrel{i.i.d.}{\\sim} N(\\mu,\\sigma^2)$\n",
        "\n",
        "*Prior distributions*\n",
        "\n",
        "$\\mu \\mid \\sigma^2 N(\\mu_0, \\sigma^2/\\kappa_0)$ with $\\mu_0=1.9$ and\n",
        "$\\kappa_0=1$.\n",
        "\n",
        "$\\sigma^2 \\sim \\text{Inv-}\\chi^2_{\\nu_0}(\\sigma_0^2)$ with $\\nu_0=1$ and\n",
        "$\\sigma_0^2=(0.1)^2$.\n",
        "\n",
        "We set our seed for reproducible results"
      ],
      "id": "f24c4d97-145d-481b-9b01-de2188734e83"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set.seed(90)"
      ],
      "id": "59e45d50-0238-43ee-9c6b-5f32972d8cdb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set the parameters of our prior distributions"
      ],
      "id": "a5119345-604e-49e7-bb24-751e78ce5996"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mu0 = 1.9\n",
        "k0 = 1 #kappa0\n",
        "nu0 = 1\n",
        "sigma0 = 0.1"
      ],
      "id": "df036e05-9bbc-4b63-be43-d5963235f2b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the number of cycles, the data, the sample size, the sample\n",
        "mean, and the sample standard deviation"
      ],
      "id": "eebcbace-1511-4d04-be33-dda8fef56503"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "B = 500000 # number of cycles\n",
        "# data\n",
        "y = c(1.64, 1.70, 1.72, 1.74, 1.82, 1.82, 1.82, 1.90, 2.08)\n",
        "# number of observations\n",
        "n = length(y)\n",
        "# sample mean\n",
        "ybar = mean(y)\n",
        "# sample standard deviation\n",
        "s = sd(y)"
      ],
      "id": "212e5bc3-3c18-48f7-8446-96901391e5a7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the sample mean and standard deviation for our initial values."
      ],
      "id": "de4ea85c-0193-4d7a-83c5-e4ebda7df8ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Initial value for mu\n",
        "mu = mean(y)\n",
        "#Initial value for sigma\n",
        "sigma = sd(y)"
      ],
      "id": "ec11b3e2-523b-4a77-87e9-7b4ee9e35dc8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the parameters of our full conditional distributions."
      ],
      "id": "2480a74c-9a7b-4f39-97bc-4cfa8bb63fb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kn = k0 + n\n",
        "mun = (k0 * mu0 + n * ybar) / kn\n",
        "nun = nu0 + n + 1"
      ],
      "id": "0162c950-d543-45db-aff7-5ff75f230d1a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now implement our Gibbs sampler."
      ],
      "id": "aead7333-838d-4e85-a84d-1ef7437ca2b8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sigmasqpost = numeric(B)\n",
        "mupost = numeric(B)\n",
        "for (i in 1:B) {\n",
        "    mu = rnorm(1, mun, sigma/sqrt(kn))\n",
        "\n",
        "    #parameter for full conditional posterior of sigma^2\n",
        "    ssqn = (nu0 * sigma0^2 + k0 * (mu - mu0)^2 + (n - 1) * s^2 + n * (ybar - mu)^2)/nun\n",
        "\n",
        "    # draw from full conditional of sigmasq\n",
        "    sigmasq = rinvchisq(1, df = nun, scale = ssqn)\n",
        "    sigma = sqrt(sigmasq)\n",
        "\n",
        "    # draw from full conditional of mu\n",
        "    mupost[i] = mu\n",
        "    sigmasqpost[i] = sigmasq\n",
        "}"
      ],
      "id": "ee7248f1-0364-458a-adfb-0e720326eded"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In *Bayesian Data Analysis, 3rd edition*, Gelman et al. provide the\n",
        "exact marginal posterior distributions for $mu$ and $\\sigma^2$.\n",
        "\n",
        "$\\mu \\mid y \\sim t_{\\nu_n}(\\mu_n, \\tau^2_n/\\kappa_n)$\n",
        "\n",
        "and\n",
        "\n",
        "$\\sigma^2\\mid y \\sim \\text{Inv-}\\chi^2_{\\nu_n}(\\tau_n^2).$\n",
        "\n",
        "Let’s compare the results from our Gibbs sampler with the true marginal\n",
        "posterior distributions."
      ],
      "id": "488db5ce-e15f-46e3-a87d-17ee7f78dc9e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define nun and taunsq\n",
        "vn = nu0 + n\n",
        "taunsq = (nu0*sigma0^2 + (n - 1) * s^2 + k0 * n/kn * (ybar - mu0)^2)/vn\n",
        "\n",
        "# plot approximate posterior density for mu\n",
        "plot(density(mupost), main = \"\",\n",
        "     xlab = \"mu\", xlim = c(1.6, 2))\n",
        "# plot true posterior density for mu\n",
        "x = seq(-1, 3, len = 1001)\n",
        "lines(x, dst(x, df = nun, mean = mun, sigma = sqrt(taunsq/kn)),\n",
        "      col = \"orange\")\n",
        "title(\"Posterior Density for mu\")\n",
        "legend(\"topright\", legend = c(\"Gibbs\", \"true\"), col = c(\"black\", \"orange\"),\n",
        "    lwd = 1)"
      ],
      "id": "54f520e9-479a-418c-9a6e-98229d9dab3e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot marginal posterior for sigmasq\n",
        "plot(density(sigmasqpost), main = \"\",\n",
        "     xlab = \"sigmasq\", xlim = c(0, 0.1))\n",
        "x = seq(0, 0.1, len = 1001)\n",
        "lines(x, dinvchisq(x, df = vn, scale = taunsq), col = \"orange\")\n",
        "title(\"Posterior Density for sigmasq\")\n",
        "legend(\"topright\",\n",
        "       legend = c(\"Gibbs\", \"True\"),\n",
        "       col = c(\"black\", \"orange\"),\n",
        "       lwd = 1)"
      ],
      "id": "8e598da2-d0f8-4cdd-a27f-3595f86df858"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#posterior quantiles for mu\n",
        "p = c(0.01, 0.10, 0.25, 0.5, 0.75, 0.90, 0.99)\n",
        "quantile(mupost, prob = p)\n",
        "qst(p, df = nun, mean = mun, sigma = sqrt(taunsq/kn))"
      ],
      "id": "2dc5b369-343f-4cdd-b3d3-42876f04d7ec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#posterior quantiles for sigmasq\n",
        "quantile(sigmasqpost, prob = p)\n",
        "qinvchisq(p, df = vn, scale = taunsq)"
      ],
      "id": "e0fb04c8-13da-4797-8f68-2071f4555011"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#95% central credible interval for mu\n",
        "quantile(mupost, c(.025, .975))\n",
        "qst(c(0.025, 0.975), df = nun, mean = mun, sigma = sqrt(taunsq/kn))"
      ],
      "id": "1fce79b8-661c-4c84-8bab-4f20ce5065e2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#95% central credible interval for sigmasq\n",
        "quantile(sigmasqpost, c(.025, .975))\n",
        "qinvchisq(c(0.025, 0.975), df = vn, scale = taunsq)"
      ],
      "id": "23a07f14-7c0a-46b7-b58e-e102fb5db373"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#plot steps of gibbs sampler for 100 iterations\n",
        "plot_mcmc_path(cbind(mupost, sigmasqpost), ncycles = 100,\n",
        "               xlab = expression(mu), ylab = expression(sigma^2))"
      ],
      "id": "10310d56-70fd-45aa-bbd3-aaf7b888406f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#plot cycles of gibbs sampler for 100 iterations\n",
        "plot_mcmc_path(cbind(mupost, sigmasqpost), ncycles = 100, type = \"cycle\",\n",
        "               xlab = expression(mu), ylab = expression(sigma^2))"
      ],
      "id": "8f479293-e184-4a3b-8461-22db9f4a5fc0"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Example:  Multivariate normal with semi-conjugate prior -->"
      ],
      "id": "ac20b7e7-c793-4df1-b0c0-7739670b56e3"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Data distribution:  y_1,y_2,…,y_n |μ,Σ∼┴(i.i.d.) N(μ,Σ) with each vector having length d. -->"
      ],
      "id": "6d541aa9-dd91-4f49-8d5a-39207ca7fa71"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Prior distributions:  -->"
      ],
      "id": "10933d14-7318-4447-87b2-00379f1a560b"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- μ∼N(μ_0,Λ_0) and Σ∼ Inv-Wishart_(ν_0 ) ( Κ_0^(-1)), with  -->"
      ],
      "id": "5a1ecd86-427a-4d8b-a2f9-bb89b6b113d2"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- p(Σ)∝|Σ|^(-(ν_0+d+1)/2)  exp⁡(-1/2 tr(Κ_0 Σ^(-1) )). -->"
      ],
      "id": "f567db15-6599-4f23-8036-fbdcbe8760da"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!--   -->"
      ],
      "id": "8cc3d010-4ca0-4e7b-bf7d-27c4e3ae39ec"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- p(μ,Σ│y)∝ -->"
      ],
      "id": "f956fda8-9fc1-4000-8052-083be651d24c"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!--   -->"
      ],
      "id": "df218e4e-6b8f-4c94-9092-03303ea568e6"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Derive the full conditional distributions:  -->"
      ],
      "id": "d6e52442-0ee7-43c2-a8c4-213ff9f9dc75"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!--   -->"
      ],
      "id": "c63c5a8b-871a-4810-a6bd-80b95dda7606"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Full conditional distributions: -->"
      ],
      "id": "3449afd9-7653-4627-9e7e-cd1901eae36c"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- μ|Σ,y∼N(μ_n,Λ_n), where -->"
      ],
      "id": "15111700-aa9f-4dc0-9307-79e3cb701b28"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- μ_n=Λ_n (Λ_0^(-1) μ_0+nΣ^(-1) y ̅ )   -->"
      ],
      "id": "af333d37-00ab-45d0-b37c-8f00e846a2ff"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- and -->"
      ],
      "id": "cc2c6a31-ac63-427c-acc7-6abfadc47bf8"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!--  Λ_n^(-1)=Λ_0^(-1)+nΣ^(-1). -->"
      ],
      "id": "e4334c93-016e-4aa7-bb36-ed02bc87a418"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Σ|μ,y∼  Inv-Wishart_(ν_n ) (K_n^(-1 ))with ν_n=ν_0+n, -->"
      ],
      "id": "8eb9536a-6851-4a90-bfdc-f3af300cbdeb"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- K_n=K_0+S_μ, -->"
      ],
      "id": "b717a647-4c2d-4c0c-a430-caa4e80581cc"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- and -->"
      ],
      "id": "c5b730f3-293f-44b5-b672-ef64e8f3d9bb"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- S_μ=∑_(i=1)^n▒〖(y_i-μ) (y_i-μ)^T.〗 -->"
      ],
      "id": "36a7bb20-431f-4336-89a7-c5bdf59ef7f6"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- A result from linear algebra says that -->"
      ],
      "id": "be27a031-947d-4cb4-8e90-9b3b91508a2b"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- ∑_(i=1)^n▒〖(y_i-μ) Σ^(-1) (y_i-μ)^T 〗=tr(S_μ Σ^(-1)), -->"
      ],
      "id": "d8e5c6c8-4b55-46e2-a22e-fe683de0a6c2"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- where  -->"
      ],
      "id": "11d5e3ef-2c9c-40af-9d3c-af353f456d48"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- S_μ=∑_(i=1)^n▒〖(y_i-μ) (y_i-μ)^T.〗 -->"
      ],
      "id": "a03ef31a-912a-4938-be3e-54cae79edc8a"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- S_μ is the residual sum of squares matrix for the vectors y_1,y_2,…,y_n if the population mean is presumed to be μ.   -->"
      ],
      "id": "b627ae21-eeef-4840-81c3-3d70624c3bbc"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!--   -->"
      ],
      "id": "43ed99ca-c1f2-4f12-a074-6acacde538e4"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Example: Reading Scores -->"
      ],
      "id": "805bd537-7e4a-4d57-83dc-bff06cd9ccb5"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- A sample of 22 children are given reading comprehension tests before and after receiving a particular instructional method.  Each student will then have two scores denoting the pre- and post-instructional scores. -->"
      ],
      "id": "506fa2fe-183a-4f05-96e1-f5c146c799e1"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Each row of the data set is a two-dimensional vector representing a single case, distributed N(μ,Σ). -->"
      ],
      "id": "54b07387-1150-49d9-937f-2e26f33c61b2"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!--   -->"
      ],
      "id": "c28718a0-55b0-4b58-a0e7-333f0c425ec5"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- The exam was designed to give an average score around 50 out of 100, so set μ_0=(50,50).  -->"
      ],
      "id": "244c2e1d-89ca-4a93-8e46-689f77edd5d8"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Since the true mean cannot be below 0 or above 100, we want the prior variances to keep μ inside this range [0, 100] with high probability. -->"
      ],
      "id": "24e8b4d4-eb12-4783-b150-068de7d9cf8e"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Thus, we want Λ_0≈[■(625&312.5@312.5&625)], which would mean that the prior probability that the marginal mean is outside [0, 100] is only 0.05.  This also accounts for the fact that the two exams measure similar things, so we think the correlation between the means is around 0.5.  -->"
      ],
      "id": "ca7cd9fe-5fd6-4ca9-944d-0835d1a84dd7"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Since E(Inv-Wishart_(ν_0 ) (K_0^(-1)))=K_0/(ν_0-d-1)), ν_0=4 will loosely center Σ around K_0. -->"
      ],
      "id": "40cac491-dc0b-442c-bf66-80cafb43182c"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!--   -->"
      ],
      "id": "60515efd-2bff-47c1-bb1f-3f2add24ae6b"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- What is the probability that the post-instruction mean is greater than the pre-instruction mean?   -->"
      ],
      "id": "3c8139fa-000e-423b-b63a-6ac6ac3dab51"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- What is the probability that the post-instruction test score is greater than the pre-instruction test score for a new student? -->"
      ],
      "id": "91a49b58-f18f-4aac-a575-2f007d731fe0"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Construct a Gibbs sampler to sample from the posterior distribution for μ and Σ. -->"
      ],
      "id": "a53b8398-9ec8-403a-a4d0-d6190289fd4b"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!--   -->"
      ],
      "id": "277ced94-589c-48d7-8c5e-0b32d07cdf5e"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Data distribution: y|μ,Σ∼┴(i.i.d.) N(μ,Σ). -->"
      ],
      "id": "ad382055-145d-4e90-94dc-0ad173c489b1"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Prior distributions:   -->"
      ],
      "id": "5cff2476-8697-49c3-8e39-5c412c532737"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- μ∼N(μ_0,Λ_0) with μ_0=(50,50) and Λ_0=[■(625&312.5@312.5&625)]. -->"
      ],
      "id": "d92c7be9-82ea-482e-b806-b5ec1f205344"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<!-- Σ∼ Inv-Wishart_(ν_0 ) (K_0^(-1)) with ν_0=4 and K_0=[■(625&312.5@312.5&625)]. -->"
      ],
      "id": "e43d9b70-b65f-4d0e-9469-20241ba31fc2"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R"
    }
  }
}