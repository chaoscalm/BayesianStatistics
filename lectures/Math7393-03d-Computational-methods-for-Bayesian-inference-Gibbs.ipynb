{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Computational methods for Bayesian inference\n",
        "\n",
        "Joshua French\n",
        "\n",
        "To open this information in an interactive Colab notebook, click the Open in Colab graphic below.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jfrench/BayesianStatistics/blob/master/lectures/Math7393-03d-Computational-methods-for-Bayesian-inference-Gibbs.ipynb\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\"> </a>\n",
        "\n",
        "We will need certain packages to be available for this notebook. The code below will check if they are installed and install them if necessary.\n",
        "\n",
        "We now plot the sample paths of our chains for the first ten cycles. We use a function, `plot_mcmc_path` from the **bayesutils** package on GitHub."
      ],
      "id": "c4728627-caa8-4121-ad10-37414516fa37"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# see if remotes package is available\n",
        "if (!require(\"remotes\", quietly = TRUE)) {\n",
        "  # if not, then install package\n",
        "  install.packages(\n",
        "    \"remotes\",\n",
        "    repos = \"https://cran.rstudio.com/\"\n",
        "    )\n",
        "}\n",
        "# see if bayesutils package is available\n",
        "if (!require(\"bayesutils\", quietly = TRUE)) {\n",
        "  # if not, then install package\n",
        "  remotes::install_github(\"jfrench/bayesutils\")\n",
        "  library(bayesutils)\n",
        "}\n",
        "# see if autoimage package is available\n",
        "if (!require(\"autoimage\", quietly = TRUE)) {\n",
        "  # if not, then install package\n",
        "  install.package(\"autoimage\")\n",
        "  library(autoimage,\n",
        "          repos = \"https://cran.rstudio.com/\",\n",
        "          quietly = TRUE)\n",
        "}"
      ],
      "id": "8e324b21-71dc-4e9f-abc7-3939f3914e20"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to MCMC Methods\n",
        "\n",
        "-   A *stochastic process* is a family of random variables $\\{\\theta^{(t)}\\}_{t\\in T}$, where $T$ is a subset of $[0, \\infty)$.\n",
        "    -   $\\theta^{(t)}$ denotes the stochastic process at time $t$.\n",
        "    -   The value $\\theta^{(t)}$ takes at time $t$ is known as the *state* of the process at time $t$.\n",
        "    -   We only consider discrete-time stochastic processes with $T=\\{0,1,2,…\\}$.\n",
        "-   The *state space* of a stochastic process is the set of all possible values the process takes.\n",
        "-   A *Markov chain* is a stochastic process $\\{\\theta^{(0)}, \\theta^{(1)}, \\ldots, \\theta^{(B)}\\}$ such that $$p(\\theta^{(t+1)} | \\theta^{(t)}, \\theta^{(t-1)}, \\ldots, \\theta^{(0)}) = p(\\theta^{(t+1)} | \\theta^{(t)}).$$\n",
        "    -   $p(\\theta^{(t+1)} | \\theta^{(t)})$ is often called the *transition distribution*.\n",
        "-   Markov chain Monte Carlo (MCMC) methods attempt to draw samples from a target distribution when sampling directly from the target distribution is impossible or computationally expensive.\n",
        "    -   The samples form a Markov chain.\n",
        "-   MCMC methods are constructed so that the (limiting) distribution of the Markov chain converges to the target distribution.\n",
        "    -   The distribution producing the samples at each step of the Markov chain becomes more like the target distribution at each step of the chain.\n",
        "-   A Markov chain converges to a *stationary distribution* when the Markov chain is irreducible, aperiodic, and positive recurrent.\n",
        "    -   In layman’s terms, for any state $i$ and $j$, we can travel from $i$ to $j$ in a finite number of steps with probability 1, and then we will travel back to $i$, but not in a specific pattern or number of steps.\n",
        "    -   This ensures that we adequately explore the entire support of our target distribution\n",
        "\n",
        "An effective MCMC method has two main properties:\n",
        "\n",
        "1.  It must be easy to draw from the $p(\\theta^{(t+1)}|\\theta^{(t)})$.\n",
        "2.  The stationary distribution of the Markov chain must match our target distribution.\n",
        "\n",
        "To construct a Markov chain using an MCMC algorithm:\n",
        "\n",
        "-   Specify an initial value, $\\theta^{(0)}$, for the chain.\n",
        "    -   Often this is a “likely” value of $\\theta$.\n",
        "-   For $t = 1,2, \\ldots, B$, draw samples from $p(\\theta^{(t+1)}|\\theta^{(t)})$ until $B$ is large enough that the stationary distribution is reached.\n",
        "-   After the chain has been implemented, check the convergence of the simulated sequence (or at least verify that there isn’t clear evidence that the chain hasn’t converged).\n",
        "    -   This is VERY important.\n",
        "\n",
        "Concluding thoughts:\n",
        "\n",
        "-   The *Gibbs* and *Metropolis-Hastings* algorithms are the most well-known MCMC algorithms.\n",
        "    -   They are designed so that the stationary distribution matches the target distribution.\n",
        "-   MCMC methods are most popularly used in Bayesian statistics.\n",
        "    -   In Bayesian statistics, the target distribution is generally the posterior distribution, $p(\\theta | y)$.\n",
        "\n",
        "# Gibbs sampling\n",
        "\n",
        "-   The *Gibbs sampling* algorithm (or *Gibbs sampler*) is the most popular Markov chain Monte Carlo (MCMC) method.\n",
        "-   The goal of the Gibbs sampler is to draw samples from a target distribution.\n",
        "-   The Gibbs sampling algorithm produces samples from the target distribution by successively drawing samples from the full conditional distributions of the target distribution.\n",
        "    -   The *full conditional distribution* of a random vector is the distribution of the random vector conditional on all the other random variables in the joint (i.e., target) distribution.\n",
        "\n",
        "Some notation and terminology:\n",
        "\n",
        "-   Let $\\theta$ be the vector of random variables comprising all variables of the target distribution, $p(\\theta | y)$.\n",
        "-   Partition $\\theta$ into $d$ components, i.e., $\\theta = (\\theta_1, \\theta_2, \\ldots, \\theta_d)$.\n",
        "    -   Each component could be a (single) random variable or a random vector.\n",
        "-   $\\theta_{-j}$ denotes the vector containing all components in $\\theta$ except $\\theta_j$, i.e., $$\\theta_{-j} = (\\theta_1, \\theta_2, \\ldots, \\theta_{j-1}, \\theta_{j+1}, \\ldots, \\theta_d).$$\n",
        "-   The *full conditional distribution* of $\\theta_j$, denoted $p(\\theta_j | \\theta_{-j}, y)$, is the distribution of component $\\theta_j$ conditional on knowing the value of all other components, $\\theta_{-j}$, and the data, $y$.\n",
        "-   After we have drawn samples from the full conditional distribution of each component (i.e., drawn samples from $p(\\theta_{j} | \\theta_{-j}^{(t-1)}, y)$ for $j=1,2,\\ldots,d$) we have completed a *cycle*.\n",
        "\n",
        "More notation:\n",
        "\n",
        "-   $\\theta_j^{(t)}$ denotes the sampled value of $\\theta_j$ in cycle $t$ and $\\theta^{(t)}$ the vector of all values sampled in cycle $t$.\n",
        "-   $\\theta_{-j}^{(t-1)}$ denotes the most current value of all $d$ components of $\\theta$ **except** $\\theta_j$, i.e., $$\\theta_{-j}^{(t-1)} = (\\theta_1^{(t)}, \\theta_2^{(t)}, \\ldots, \\theta_{j-1}^{(t)}, \\theta_{j+1}^{(t-1)}, \\ldots, \\theta_{d}^{(t-1)}).$$\n",
        "-   $p(\\theta_j | \\theta_{-j}^{(t-1)}, y)$ denotes the full conditional distribution of $\\theta_j$ conditional on $\\theta_{-j}$ being fixed at $\\theta_{-j}^{(t-1)}$ and the data being fixed at $y$.\n",
        "\n",
        "The basic Gibbs sampling algorithm is:\n",
        "\n",
        "1.  Choose starting values for all of your components, i.e., $\\theta^{(0)} = (\\theta^{(0)}_1, \\theta^{(0)}_2, \\ldots, \\theta^{(0)}_d)$.\n",
        "2.  Set $t = 1$.\n",
        "3.  Draw $\\theta_j^{(t)}$ from the full conditional distribution $p(\\theta_j | \\theta_{-j}^{(t-1)}, y)$ for $j = 1, 2, \\ldots, d$.\n",
        "4.  Increment $t$.\n",
        "5.  Repeat steps 3 and 4 until convergence.\n",
        "\n",
        "# Example: Gibbs sampler (bivariate normal)\n",
        "\n",
        "This example appears in Bayesian Data Analysis, 3rd edition, by Gelman et al. (2013).\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y | \\theta \\sim N(\\theta, \\Sigma)$ is a bivariate normal distribution with unknown mean $\\theta = (\\theta_1, \\theta_2)$ and known covariance matrix\n",
        "\n",
        "$$\n",
        "\\Sigma =\n",
        "\\begin{bmatrix}\n",
        " 1 & \\rho \\\\\n",
        "\\rho & 1\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "*Prior distribution*\n",
        "\n",
        "The prior for $\\theta$ is an improper uniform over the real line, i.e., $p(\\theta_1,\\theta_2)\\propto1$.\n",
        "\n",
        "(Why? Because it makes the example easier!)\n",
        "\n",
        "*Posterior distribution*\n",
        "\n",
        "Assuming we observe a single observation $y=(y_1,y_2)$, $$\\theta | y \\sim N(y, \\Sigma).$$\n",
        "\n",
        "Let’s derive the full conditional distributions for $\\theta_1$ and $\\theta_2$.\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "*Full conditional distributions*\n",
        "\n",
        "$\\theta_1 | \\theta_2, y \\sim N(y_1 + \\rho(\\theta_2-y_2),1-\\rho^2)$\n",
        "\n",
        "$\\theta_2 | \\theta_1, y \\sim N(y_2 + \\rho(\\theta_1-y_1), 1-\\rho^2)$\n",
        "\n",
        "Let’s sample from the posterior distribution using a Gibbs sampler assuming $y=(0,0)$ and $\\rho=0.8$.\n",
        "\n",
        "First, we set some of the needed parameters."
      ],
      "id": "892455e6-9724-453c-9614-1c5fcc4bb3e4"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set parameters\n",
        "rho = .8\n",
        "sigma = sqrt(1 - rho^2)\n",
        "#observed data\n",
        "y1 = 0\n",
        "y2 = 0"
      ],
      "id": "a251532d-d5d8-49c2-a920-777110422917"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s create a function, `gibbs`, to do the sampling. The function takes:\n",
        "\n",
        "-   `B`: the number of cycles to run.\n",
        "-   `theta`: the vector of initial values."
      ],
      "id": "034e8184-1915-4072-9bb4-38462926ee9c"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "gibbs = function(B, theta) {\n",
        "  #create matrix to store samples\n",
        "  theta_sims = matrix(0, nrow = B + 1, ncol = 2)\n",
        "  theta_sims[1,] = theta\n",
        "  # run gibbs sampler for B cycles\n",
        "  for (i in 2:(B+1)) {\n",
        "    # determine full conditional mean for theta1\n",
        "    m1 = y1 + rho * (theta[2] - y2)\n",
        "    # simulate from full conditional distribution for theta1\n",
        "    theta[1] = rnorm(1, m1, sigma)\n",
        "    # determine full conditional mean for theta2\n",
        "    m2 = y2 + rho * (theta[1] - y1)\n",
        "    # simulate from full conditional distribution for theta1\n",
        "    theta[2] = rnorm(1, m2, sigma)\n",
        "    # save sample\n",
        "    theta_sims[i, ] = theta\n",
        "  }\n",
        "  return(theta_sims)\n",
        "}"
      ],
      "id": "b5fbc2a6-a96e-4853-8290-a89010fc8c90"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s run an initial chain of 1000 cycles with a starting value $\\theta=(-2.5, -2.5)$."
      ],
      "id": "b6b4e6a4-9f62-460d-87a7-4725e40e59fa"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run initial chain\n",
        "chain1 = gibbs(B = 1000, theta = c(-2.5, -2.5))"
      ],
      "id": "1d61f6a5-8acc-4e28-96f1-a177d5e50a67"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s draw a “sand” plot of our first chain."
      ],
      "id": "b3dc97c9-6dba-46ec-9389-1ae5ad21901f"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot(chain1, pch = \".\",\n",
        "     xlab = expression(theta[1]),\n",
        "     ylab = expression(theta[2]))\n",
        "title(\"Samples from Gibbs sampler\")"
      ],
      "id": "0a9e8008-39be-4b83-a37d-a2b3f3b377a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now run 3 more chains with different starting values."
      ],
      "id": "ff3aa0d6-863f-4657-9668-b73931ee0e7a"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain2 = gibbs(B = 1000, c(-2.5, 2.5))\n",
        "chain3 = gibbs(B = 1000, c(2.5, -2.5))\n",
        "chain4 = gibbs(B = 1000, c(2.5, 2.5))"
      ],
      "id": "9354fcf8-a10f-42ba-82b0-de276b57c1f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now plot the samples from all 4 chains in one graphic."
      ],
      "id": "72e5fba0-59c3-4c10-ae92-62c7d1c92e64"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# chain 1\n",
        "plot(chain1, pch = \".\",\n",
        "     xlab = expression(theta[1]),\n",
        "     ylab = expression(theta[2]))\n",
        "# chains 2-4\n",
        "points(chain2, pch = \".\", col = \"orange\")\n",
        "points(chain3, pch = \".\", col = \"blue\")\n",
        "points(chain4, pch = \".\", col = \"grey\")\n",
        "# add legend\n",
        "legend(\"topleft\", pch = 20,\n",
        "       col = c(\"black\", \"orange\", \"blue\", \"grey\"),\n",
        "       legend = c(\"Chain 1\", \"Chain 2\", \"Chain 3\", \"Chain 4\"))\n",
        "title(\"Samples from Gibbs sampler\")"
      ],
      "id": "3dabeda6-977d-4d27-90f3-d908853db2de"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now plot the first 10 cycles of the 4 chains using the `plot_mcmc_path` function from the **bayesutils** package.\n",
        "\n",
        "`plot_mcmc_path` takes:\n",
        "\n",
        "-   `x`: a matrix with 2 columns or a list of 2 column matrices.\n",
        "-   `ncycles`: the number of cycles to plot."
      ],
      "id": "8261bbc6-e6df-4a20-82a5-d27b685def6d"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_mcmc_path(\n",
        "  list(chain1, chain2, chain3, chain4),\n",
        "  ncycles = 10,\n",
        "  xlim = c(-2.5, 2.5),\n",
        "  ylim = c(-2.5, 2.5),\n",
        "  xlab = expression(theta[1]),\n",
        "  ylab = expression(theta[2]),\n",
        "  main = \"First 10 cycles of each chain\"\n",
        ")"
      ],
      "id": "0157460b-df47-4600-a693-b6fe17762dc9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example: Normal distribution with $\\mu$ and $\\sigma^2$ unknown and conjugate prior\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y_1,\\ldots,y_n \\mid \\mu,\\sigma^2 \\stackrel{i.i.d.}{\\sim} N(\\mu,\\sigma^2)$.\n",
        "\n",
        "*Prior distribution*\n",
        "\n",
        "$\\mu \\mid \\sigma^2 \\sim N(\\mu_0, \\sigma^2/\\kappa_0)$\n",
        "\n",
        "$\\sigma^2 \\sim \\text{Inv-}\\chi^2_{\\nu_0}(\\sigma_0^2)$\n",
        "\n",
        "where\n",
        "\n",
        "$p(\\sigma^2) \\propto (\\sigma^2)^{-\\left(\\frac{\\nu_0}{2} + 1\\right)} \\exp\\left(-\\frac{\\nu_0 \\sigma_0^2}{2\\sigma^2}\\right)$.\n",
        "\n",
        "*Data density*\n",
        "\n",
        "$p(y \\mid \\mu,\\sigma^2) \\propto$\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "$p(\\mu,\\sigma^2\\mid y) \\propto$\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "Derive the full conditional distributions\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "*Full conditional distributions*\n",
        "\n",
        "$\\mu \\mid \\sigma^2, y \\sim N(\\mu_n, \\tau_n^2)$ with\n",
        "\n",
        "$$\n",
        "\\mu_n = \\frac{\\kappa_0}\n",
        "{\\sigma^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "\\tau_n^2=\\frac{1}{\\frac{\\kappa_0}{\\sigma^2}+\\frac{n}{\\sigma^2}}=\\frac{\\sigma^2}{\\kappa_0+n}.\n",
        "$$ $\\sigma^2 \\mid \\mu, y \\sim \\text{Inv-}\\chi^2_{\\nu_n}(s_n^2)$\n",
        "\n",
        "with\n",
        "\n",
        "$$\n",
        "\\nu_n = \\nu_0 + n + 1\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "s_n^2=\\frac{\\mu_0 \\sigma_0^2+\\kappa_0 (\\mu-\\mu_0 )^2+(n-1) s^2+n(\\bar{y}-\\mu)^2}{\\nu_n}.\n",
        "$$\n",
        "\n",
        "**Example: Midge Data**\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "Grogan and Wirth (1981) provide data on the wing length in millimeters of nine members of a species of midge (small, two-winged flies). From these nine measurements, we wish to make inference on the population mean $\\mu$ and population variance $\\sigma^2$. Create a Gibbs sampler for the parameters $\\mu$ and $\\sigma^2$.\n",
        "\n",
        "Studies of other populations suggest that the true mean should be around 1.9 mm with a standard deviation of 0.1. However, this population may be different from the others, so we choose $\\kappa_0 = \\nu_0 = 1$ so that the prior distributions are only weakly centered around these estimates from other populations.\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y_1,\\ldots,y_n \\mid \\mu, \\sigma^2 \\stackrel{i.i.d.}{\\sim} N(\\mu,\\sigma^2)$\n",
        "\n",
        "*Prior distributions*\n",
        "\n",
        "$\\mu \\mid \\sigma^2 N(\\mu_0, \\sigma^2/\\kappa_0)$ with $\\mu_0=1.9$ and $\\kappa_0=1$.\n",
        "\n",
        "$\\sigma^2 \\sim \\text{Inv-}\\chi^2_{\\nu_0}(\\sigma_0^2)$ with $\\nu_0=1$ and $\\sigma_0^2=(0.1)^2$.\n",
        "\n",
        "We set our seed for reproducible results"
      ],
      "id": "c494dcbb-a684-40e9-9f60-14cf48b29747"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "set.seed(90)"
      ],
      "id": "525837a7-da54-4ee6-b15a-646081f9b939"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set the parameters of our prior distributions"
      ],
      "id": "03c99eb6-1792-4e91-9cee-b5d5e5c7abcc"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "mu0 = 1.9\n",
        "k0 = 1 #kappa0\n",
        "nu0 = 1\n",
        "sigma0 = 0.1"
      ],
      "id": "6a1ba5ba-dcef-45df-851e-581e68e44da1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the number of cycles, the data, the sample size, the sample mean, and the sample standard deviation"
      ],
      "id": "24e34030-05cd-424b-9c8c-ed2b1e937650"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "B = 500000 # number of cycles\n",
        "# data\n",
        "y = c(1.64, 1.70, 1.72, 1.74, 1.82, 1.82, 1.82, 1.90, 2.08)\n",
        "# number of observations\n",
        "n = length(y)\n",
        "# sample mean\n",
        "ybar = mean(y)\n",
        "# sample standard deviation\n",
        "s = sd(y)"
      ],
      "id": "f5cd34ff-5bf0-4c31-951c-a2d9d4c57890"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the sample mean and standard deviation for our initial values."
      ],
      "id": "f3c19a73-c90a-4af6-8781-8cc2f132cd0b"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Initial value for mu\n",
        "mu = mean(y)\n",
        "#Initial value for sigma\n",
        "sigma = sd(y)"
      ],
      "id": "4492ee7b-3181-41e3-86f3-52cd626fed45"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the parameters of our full conditional distributions."
      ],
      "id": "455d7875-7756-418d-954a-3888cc60b61f"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "kn = k0 + n\n",
        "mun = (k0 * mu0 + n * ybar) / kn\n",
        "nun = nu0 + n + 1"
      ],
      "id": "4a6aa786-1b76-4bfa-834f-eb3b31f764a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now implement our Gibbs sampler."
      ],
      "id": "83bc4df5-56ac-4621-a097-ab6dad4c4b05"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "sigmasqpost = numeric(B)\n",
        "mupost = numeric(B)\n",
        "for (i in 1:B) {\n",
        "    mu = rnorm(1, mun, sigma/sqrt(kn))\n",
        "\n",
        "    #parameter for full conditional posterior of sigma^2\n",
        "    ssqn = (nu0 * sigma0^2 + k0 * (mu - mu0)^2 + (n - 1) * s^2 + n * (ybar - mu)^2)/nun\n",
        "\n",
        "    # draw from full conditional of sigmasq\n",
        "    sigmasq = rinvchisq(1, df = nun, scale = ssqn)\n",
        "    sigma = sqrt(sigmasq)\n",
        "\n",
        "    # draw from full conditional of mu\n",
        "    mupost[i] = mu\n",
        "    sigmasqpost[i] = sigmasq\n",
        "}"
      ],
      "id": "4b0b4d88-e7e1-450d-b845-8edc897f32f3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In *Bayesian Data Analysis, 3rd edition*, Gelman et al. provide the exact marginal posterior distributions for $\\mu$ and $\\sigma^2$:\n",
        "\n",
        "$\\mu \\mid y \\sim t_{\\nu_n}(\\mu_n, \\tau^2_n/\\kappa_n)$\n",
        "\n",
        "and\n",
        "\n",
        "$\\sigma^2\\mid y \\sim \\text{Inv-}\\chi^2_{\\nu_n}(\\tau_n^2)$,\n",
        "\n",
        "where\n",
        "\n",
        "$\\nu_n = \\nu_0 + n$\n",
        "\n",
        "and\n",
        "\n",
        "$\\tau_n^2 = (\\nu_0\\sigma_0^2 + (n - 1)s^2 + \\kappa_0 n/\\kappa_n (\\bar{y} - \\mu_0)^2)/\\nu_n$.\n",
        "\n",
        "Note that this $\\nu_n$ and $\\tau_n^2$ differ from the $\\nu_n$ and $\\tau_n^2$ defined for the full conditional distributions.\n",
        "\n",
        "Let’s compare the results from our Gibbs sampler with the true marginal posterior distributions.\n",
        "\n",
        "We plot the true and approximate marginal posterior density of $\\mu$."
      ],
      "id": "98ec8b41-4a8e-4d8e-95ae-7aaac8c35651"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define nun and taunsq\n",
        "vn = nu0 + n\n",
        "taunsq = (nu0*sigma0^2 + (n - 1) * s^2 + k0 * n/kn * (ybar - mu0)^2)/vn\n",
        "\n",
        "# plot approximate posterior density for mu\n",
        "plot(density(mupost), main = \"\",\n",
        "     xlab = \"mu\", xlim = c(1.6, 2))\n",
        "# plot true posterior density for mu\n",
        "x = seq(-1, 3, len = 1001)\n",
        "lines(x, dst(x, df = nun, mean = mun, sigma = sqrt(taunsq/kn)),\n",
        "      col = \"orange\")\n",
        "title(\"Posterior Density for mu\")\n",
        "legend(\"topright\", legend = c(\"Gibbs\", \"true\"), col = c(\"black\", \"orange\"),\n",
        "    lwd = 1)"
      ],
      "id": "a7fca822-9386-46cd-b516-31462c685eb8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the true and approximate marginal posterior density of $\\sigma^2$."
      ],
      "id": "c347bc63-39d8-4368-97c9-764e2673cb07"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot marginal posterior for sigmasq\n",
        "plot(density(sigmasqpost), main = \"\",\n",
        "     xlab = \"sigmasq\", xlim = c(0, 0.1))\n",
        "x = seq(0, 0.1, len = 1001)\n",
        "lines(x, dinvchisq(x, df = vn, scale = taunsq), col = \"orange\")\n",
        "title(\"Posterior Density for sigmasq\")\n",
        "legend(\"topright\",\n",
        "       legend = c(\"Gibbs\", \"True\"),\n",
        "       col = c(\"black\", \"orange\"),\n",
        "       lwd = 1)"
      ],
      "id": "feae78a2-2bf7-400f-a635-66343caa482b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the empirical posterior quantiles for $\\mu$."
      ],
      "id": "6ce89194-a638-4bf5-9745-117fad6078b8"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#posterior quantiles for mu\n",
        "p = c(0.01, 0.10, 0.25, 0.5, 0.75, 0.90, 0.99)\n",
        "quantile(mupost, prob = p)"
      ],
      "id": "b9d88b3a-ae99-4782-8fe6-123224ef731e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the true posterior quantiles for $\\mu$."
      ],
      "id": "363bf2dd-87bc-4e95-99af-7cf02eb639e0"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "qst(p, df = nun, mean = mun, sigma = sqrt(taunsq/kn))"
      ],
      "id": "d096277f-c929-4bc3-8f50-787b38a8960f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the empirical posterior quantiles for $\\sigma^2$."
      ],
      "id": "77a78ad2-dc18-47a2-81e1-7e18c2c06b42"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "quantile(sigmasqpost, prob = p)"
      ],
      "id": "d6ccbf6b-8e14-4648-8be7-550783945eaf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the true posterior quantiles for $\\sigma^2$."
      ],
      "id": "5461492b-1524-420b-a96d-236eba05f294"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "qinvchisq(p, df = vn, scale = taunsq)"
      ],
      "id": "0cdfd4c0-f1c9-40ec-96f5-e00d16b5b31f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the empirical 95% central posterior interval for $\\mu$."
      ],
      "id": "bcd2e177-466f-485a-81cb-6964cfa971b1"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "quantile(mupost, c(.025, .975))"
      ],
      "id": "7447b5f7-618c-4e5a-8893-94e4f24ee462"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the true 95% central posterior interval for $\\mu$."
      ],
      "id": "e9b89c66-d4e3-40b9-a834-f03508a57f54"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "qst(c(0.025, 0.975), df = nun, mean = mun,\n",
        "    sigma = sqrt(taunsq/kn))"
      ],
      "id": "8efe4379-7648-46b6-8b00-a2f78b71a3e9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the empirical 95% central posterior interval for $\\sigma^2$."
      ],
      "id": "e7d9da0b-d8a9-417a-af58-a552b40254c1"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "quantile(sigmasqpost, c(.025, .975))"
      ],
      "id": "4b91b8d7-1aad-48f6-84bb-298161c15c65"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the true 95% central posterior interval for $\\sigma^2$."
      ],
      "id": "acefc65a-8cba-48c8-b308-5c41a9ae76c6"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "qinvchisq(c(0.025, 0.975), df = vn, scale = taunsq)"
      ],
      "id": "4d4ebc87-f6bb-4ba9-aaf0-7014e61a51f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, we plot the first 100 cycles of our Gibbs sampler."
      ],
      "id": "019a5718-b483-445d-beb0-c9ddb9419064"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_mcmc_path(cbind(mupost, sigmasqpost), ncycles = 100,\n",
        "               xlab = expression(mu), ylab = expression(sigma^2))"
      ],
      "id": "6174cccc-56c6-4741-8d99-7b5947f030b8"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "#plot cycles of gibbs sampler for 100 iterations\n",
        "plot_mcmc_path(cbind(mupost, sigmasqpost),\n",
        "               ncycles = 100, type = \"cycle\",\n",
        "               xlab = expression(mu), ylab = expression(sigma^2))"
      ],
      "id": "8a208f4b-19c5-481a-b520-aaba4e194f43"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example: Multivariate normal with semi-conjugate prior\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$\\mathbf{y}_1,\\mathbf{y}_2,…,\\mathbf{y}_n \\mid \\boldsymbol{\\mu},\\boldsymbol{\\Sigma} \\stackrel{i.i.d.}{\\sim} N(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$ with each vector having length $d$.\n",
        "\n",
        "*Prior distributions*\n",
        "\n",
        "$\\boldsymbol{\\mu} \\sim N(\\boldsymbol{\\mu}_0, \\boldsymbol{\\Lambda}_0)$.\n",
        "\n",
        "$\\boldsymbol{\\Sigma} \\sim \\text{Inv-Wishart}_{\\nu_0} ( \\mathbf{Κ}_0^{-1})$.\n",
        "\n",
        "$p(\\boldsymbol{\\Sigma}) \\propto |\\boldsymbol{\\Sigma}|^{-(\\nu_0+d+1)/2} \\exp\\left(-\\frac{1}{2} \\text{tr}(\\mathbf{K}_0 \\boldsymbol{\\Sigma}^{-1})\\right).$\n",
        "\n",
        "$p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} \\mid y) \\propto$\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "Derive the full conditional distributions:\n",
        "\n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "*Full conditional distributions*\n",
        "\n",
        "$\\boldsymbol{\\mu} \\mid \\boldsymbol{\\Sigma}, y \\sim N(\\boldsymbol{\\mu}_n,\\boldsymbol{\\Lambda}_n)$, where\n",
        "\n",
        "$$\\boldsymbol{\\mu}_n=\\boldsymbol{\\Lambda_n} (\\boldsymbol{\\Lambda}_0^{-1} \\boldsymbol{\\mu}_0+n \\boldsymbol{\\Sigma}^{-1} \\bar{y})$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\\boldsymbol{\\Lambda}_n^{-1}=\\boldsymbol{\\Lambda}_0^{-1}+n\\boldsymbol{\\Sigma}^{-1}.$$\n",
        "\n",
        "$\\boldsymbol{\\Sigma}\\mid \\boldsymbol{\\mu},y \\sim \\text{Inv-Wishart}_{\\nu_n} (\\mathbf{K}_n^{-1 })$, where\n",
        "\n",
        "$$\\nu_n=\\mu_0+n,$$\n",
        "\n",
        "$$\\mathbf{K}_n=\\mathbf{K}_0+\\mathbf{S}_\\mu,$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "\\mathbf{S}_\\mu=\\sum_{i=1}^n (\\mathbf{y}_i-\\boldsymbol{\\mu}) (\\mathbf{y}_i-\\boldsymbol{\\mu})^T.\n",
        "$$\n",
        "\n",
        "A result from linear algebra says that\n",
        "\n",
        "$$\\sum_{i=1}^n (\\mathbf{y}_i-\\boldsymbol{\\mu})\\boldsymbol{\\Sigma}^{-1} (\\mathbf{y}_i-\\boldsymbol{\\mu})^T = \\text{tr}(\\mathbf{S}_\\mu \\boldsymbol{\\Sigma^{-1}})$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\\mathbf{S}_\\mu=\\sum_{i=1}^n (\\mathbf{y}_i-\\boldsymbol{\\mu}) (\\mathbf{y}_i-\\boldsymbol{\\mu})^T.$$\n",
        "\n",
        "$\\mathbf{S}_\\mu$ is the residual sum of squares matrix for the vectors $\\mathbf{y}_1,\\mathbf{y}_2,\\ldots,\\mathbf{y}_n$ if the population mean is presumed to be $\\boldsymbol{\\mu}$.\n",
        "\n",
        "**Example: Reading Scores**\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "A sample of 22 children are given reading comprehension tests before and after receiving a particular instructional method. Each student will then have two scores denoting the pre- and post-instructional scores.\n",
        "\n",
        "Each row of the data set is a two-dimensional vector representing a single case, distributed $N(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$.\n",
        "\n",
        "The exam was designed to give an average score around 50 out of 100, so set $\\boldsymbol{μ}_0=(50,50)$.\n",
        "\n",
        "Since the true mean cannot be below 0 or above 100, we want the prior variances to keep $\\boldsymbol{\\mu}$ inside this range $[0, 100]^2$ with high probability.\n",
        "\n",
        "We can use\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\Sigma} =\n",
        "\\begin{bmatrix}\n",
        " 625 & 312.5 \\\\\n",
        "312.5 & 625\n",
        "\\end{bmatrix},\n",
        "$$\n",
        "\n",
        "which would mean that the prior probability that the marginal mean is outside $[0, 100]^2$ is only 0.05.\n",
        "\n",
        "This also accounts for the fact that the two exams measure similar things, so we think the correlation between the means is around 0.5.\n",
        "\n",
        "Since $E(\\text{Inv-Wishart}_{\\nu_0} (\\mathbf{K}_0^{-1}))=\\mathbf{K}_0/(\\nu_0-d-1)$, $\\nu_0=4$ will loosely center $\\mathbf{\\Sigma}$ around $\\mathbf{K}_0$.\n",
        "\n",
        "What is the probability that the post-instruction mean is greater than the pre-instruction mean?\n",
        "\n",
        "What is the probability that the post-instruction test score is greater than the pre-instruction test score for a new student?\n",
        "\n",
        "Construct a Gibbs sampler to sample from the posterior distribution for $\\boldsymbol{\\mu}$ and $\\boldsymbol{\\Sigma}$.\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y \\mid \\boldsymbol{\\mu},\\boldsymbol{\\Sigma}\\stackrel{i.i.d.}{\\sim} N(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$.\n",
        "\n",
        "*Prior distributions*\n",
        "\n",
        "$\\boldsymbol{\\mu}\\sim N(\\boldsymbol{\\mu}_0,\\boldsymbol{\\Lambda}_0)$ with\n",
        "\n",
        "$\\boldsymbol{\\mu}_0=(50,50)$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\Lambda}_0 =\n",
        "\\begin{bmatrix}\n",
        " 625 & 312.5 \\\\\n",
        "312.5 & 625\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "$\\boldsymbol{\\Sigma} \\sim \\text{Inv-Wishart}_{\\nu_0} (\\mathbf{K}_0^{-1})$ with\n",
        "\n",
        "$\\nu_0=4$\n",
        "\n",
        "and\n",
        "\n",
        "$$\\mathbf{K}_0=\n",
        "\\begin{bmatrix}\n",
        " 625 & 312.5 \\\\\n",
        "312.5 & 625\n",
        "\\end{bmatrix}.$$\n",
        "\n",
        "We begin by loading the data."
      ],
      "id": "9aac8c61-0fe3-4ea0-97a4-0eb7a5d57d35"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load data\n",
        "y = matrix(c(\n",
        "59, 77, 43, 39, 34, 46, 32, 26, 42, 38, 38, 43, 55, 68,\n",
        "67, 86, 64, 77, 45, 60, 49, 50, 72, 59, 34, 38, 70, 48,\n",
        "34, 55, 50, 58, 41, 54, 52, 60, 60, 75, 34, 47, 28, 48,\n",
        "35, 33), ncol = 2, byrow = TRUE)\n",
        "# reformat\n",
        "y = data.frame(pretest = y[,1], posttest = y[,2])"
      ],
      "id": "82b56720-9ddc-4d68-8deb-1fd6edc07051"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set some generic parameters."
      ],
      "id": "89904ea7-1333-4aa5-867f-261466869651"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = nrow(y)\n",
        "d = ncol(y)"
      ],
      "id": "56f327c9-7d60-4afa-9c78-1a2115e7e447"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set the prior parameters."
      ],
      "id": "12b14214-5881-48cc-94a0-e0f424a82ed6"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "mu0 = c(50, 50)\n",
        "nu0 = 4\n",
        "L0 = K0 = 25^2 * matrix(c(1, .5, .5, 1), nrow = 2)"
      ],
      "id": "8e2d39a4-5b90-4308-a361-cfa40bf2119d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We calculate necessary summary quantities"
      ],
      "id": "2d4d9e45-9618-4048-95e4-24e8e798a4d7"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "ybar = colMeans(y)"
      ],
      "id": "dab4990c-9052-434e-896a-263c3a0b9ac9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We determine some posterior parameters"
      ],
      "id": "33fb5487-14cd-4243-aa3d-0e9fbade94bf"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "nun = nu0 + n"
      ],
      "id": "1fb4b047-ad41-4556-8147-5815b8d7110e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set the number of cycles."
      ],
      "id": "1d5829de-18ef-4aa3-b797-b266e200c16d"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "B = 10000"
      ],
      "id": "ca965afb-87f0-46aa-9ea5-583e5c2c1ac7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create initial guesses for $\\boldsymbol{\\mu}$, $\\boldsymbol{\\Sigma}$, and $\\mathbf{S}_\\mu$."
      ],
      "id": "eba5b54b-b857-46a7-85fb-412f6fab617c"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "mu = ybar\n",
        "Sigma = cov(y)\n",
        "# initial guess for Smu\n",
        "Smu = (n - 1) * var(y)"
      ],
      "id": "63c21a82-8c8b-4d03-8ea7-babb910e5790"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create some matrices/arrays to store our results."
      ],
      "id": "6e1d2937-f6aa-43f2-bd8b-08fb95830764"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "mupost = matrix(0, nrow = B, ncol = d)\n",
        "Sigmapost = array(0, dim = c(d, d, B))\n",
        "ytildepost = matrix(0, nrow = B, ncol = d)"
      ],
      "id": "8f26b2ae-aa84-48dd-97c6-fc1d2eb6f1cd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we execute our Gibbs sampler."
      ],
      "id": "dc0f0eab-92d6-4835-b7c0-98c68a2b055e"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "for (i in 1:B) {\n",
        "    #determine full conditional distribution of mean,\n",
        "    #simulate from distribution\n",
        "    Ln = solve(solve(L0) + n * solve(Sigma))\n",
        "    mun = Ln %*% (solve(L0) %*% mu0 + n * solve(Sigma) %*% ybar)\n",
        "    mu = c((rmvnorm(1, mu = mun, v = Ln)))\n",
        "\n",
        "    #determine full conditional distribution of Sigma,\n",
        "    #simulate from distribution\n",
        "    Smu = (t(y) - mu) %*% t(t(y) - mu)\n",
        "    Kn = K0 + Smu\n",
        "\n",
        "    Sigma = rinvwish(1, df = nun, v = Kn)[,,1]\n",
        "\n",
        "    mupost[i, ] = mu\n",
        "    Sigmapost[,,i] = Sigma\n",
        "\n",
        "    ytildepost[i, ] = rmvnorm(1, mu = mu, v = Sigma)\n",
        "}"
      ],
      "id": "f8d8b461-30e0-4a70-8d3a-bf51253d5928"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We estimate the posterior mean of $\\boldsymbol{\\mu}$."
      ],
      "id": "989afce9-ee95-432e-a851-375d5a14a7bf"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "(mean.mupost = apply(mupost, 2, mean))"
      ],
      "id": "ab949bf1-c1dd-4140-b07d-3aaa52fbdd56"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We estimate the posterior variance of $\\boldsymbol{\\mu}$."
      ],
      "id": "11fe1bc6-2210-4605-80a8-12115833edf2"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "(var.mupost = apply(mupost, 2, var))"
      ],
      "id": "d722c5b7-6776-461f-bfed-30e535c9e17e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We estimate the posterior mean of $\\boldsymbol{\\Sigma}$."
      ],
      "id": "b7c871d4-acd9-477c-9328-01f2965ad897"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "(mean.Sigmapost = apply(Sigmapost, c(1, 2), mean))"
      ],
      "id": "0803f358-d670-409a-9332-cabab6cbb69d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We estimate the posterior variance of $\\boldsymbol{\\Sigma}$."
      ],
      "id": "45d3c00f-291d-4ef6-a4c2-aeeaca79bbaf"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "(var.Sigmapost = apply(Sigmapost, c(1, 2), var))"
      ],
      "id": "31a38e14-54a1-4371-92a6-ae02bb00b9f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute some posterior quantiles for $\\boldsymbol{\\mu}$."
      ],
      "id": "951aa291-0bb6-44e3-a90e-0869470eb601"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "apply(mupost, 2, quantile, prob = c(.01, .25, .5, .75, .99))"
      ],
      "id": "8f09f42a-b554-4832-bfb5-ddec0a718145"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the posterior densities of the pre- and post-test means."
      ],
      "id": "e246cd27-be6d-44f7-8946-230410dcb8a7"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "dpretest = density(mupost[,1])\n",
        "dposttest = density(mupost[,2])\n",
        "plot(dpretest, type = \"l\", xlim = range(c(dpretest$x, dposttest$x)),\n",
        "    ylim = range(c(dpretest$y, dposttest$y)), main = \"\")\n",
        "lines(dposttest, col = \"orange\")\n",
        "legend(\"topleft\", legend = c(\"mu pretest\", \"mu postest\"),\n",
        "    col = c(\"black\", \"orange\"), lwd = c(1, 1))"
      ],
      "id": "3fb5c3f7-a931-4b77-93da-f0345788f895"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We estimate $P(\\mu_{\\text{post}} > \\mu_{\\text{pre}})$."
      ],
      "id": "f4e649fa-ede6-4e0a-a5fc-e26eb9660c72"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean(mupost[,2] > mupost[,1])"
      ],
      "id": "9590522e-94f6-46aa-8bcc-483ecd908947"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We estimate $P(\\tilde{y}_{\\text{post}} > \\tilde{y}_{\\text{pre}})$."
      ],
      "id": "9be2984c-7883-40f8-83b6-41255af334b2"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean(ytildepost[,2] > ytildepost[,1])"
      ],
      "id": "9944a6ce-9a38-4b45-9083-d31a5c82a523"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We visualize the joint posterior density of $\\boldsymbol{\\mu}$."
      ],
      "id": "619a1b3b-dcb3-47d5-9c66-3926c6a2d08f"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# estimate bivariate density\n",
        "d2d = MASS::kde2d(mupost[,1], mupost[,2], n = 50)\n",
        "# plot results\n",
        "autoimage::pimage(d2d, col = hcl.colors(64),\n",
        "                  xlab = \"mu pretest\", ylab = \"mu posttest\")\n",
        "contour(d2d, add = TRUE)\n",
        "points(mupost[1:100,], pch = 20)"
      ],
      "id": "9b9c416b-478b-4f54-a75a-0472cd619c4a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "jupyter: kernelspec: display_name: R language: R name: ir\n",
        "\n",
        "------------------------------------------------------------------------"
      ],
      "id": "d101babe-17de-431e-8ab4-96a3fe73d9e7"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}